plot(accepted_denied$x, accepted_denied$y.y / (accepted_denied$y.x + accepted_denied$y.y), type="l", col="blue", xlab="Impressions", ylab="N_denied / N_accepted", main="Denied / accepted ratio")
library(ggplot2)
# Search radius (25mi is the default)
R <- 25.0
# Blended sort radius, based on bbox
BLENDED_R <- 16.39
# Distance is counted in increments of 0.1mi (old code)
MILES_INCR <- 0.1
# Take n samples
RESO_SAMPLES <- 50
# Or top n by rank
RANK_TOP_N <- 50
sf <- subset(read.table("in/sf_points_rank.2012-03-06.csv", sep="\t", header=TRUE), !duplicated(rank))
resos <- read.table("in/resos_3months_out.2012-03-07.csv", sep=",", header=TRUE)
sf_resos <- merge(sf, resos, by="hosting_id")
# Take random samples
sf_resos <- sf_resos[sample(1:nrow(sf_resos), RESO_SAMPLES, replace=FALSE),]
# Take top n
# sf_resos <- subset(sf_resos, rank > 0 & rank <= RANK_TOP_N)
## Additonal values
sf_resos$d_R <- sf_resos$distance / R
sf_resos$o_1 <- sf_resos$nights_1month / 31
sf_resos$o_2 <- sf_resos$nights_2month / 62
sf_resos$o_3 <- sf_resos$nights_3month / 93
for (i in 1:nrow(sf_resos)) {
# Make log work. < 1 point are all treated as equally bad
if (sf_resos$points[i] < 1) {
sf_resos$log_p[i] = 0.0
}
else {
sf_resos$log_p[i] <- log10(sf_resos$points[i])
}
}
# Weights
W_p <- 0.3 # Note: points aren't normalized. The max is around 2000, so 0.3 * log10() gives just under 1.0
W_d <- -0.6
W_o <- -0.2
sf_resos$weighted_points <- W_p * sf_resos$log_p
sf_resos$weighted_distance <- W_d * sf_resos$d_R
sf_resos$weighted_occupancy <- W_o * sf_resos$o_1
sf_resos$rank2 <- sf_resos$weighted_points + sf_resos$weighted_distance + sf_resos$weighted_occupancy
# min <- min(sf_resos$rank2)
# sf_resos$rank2 <- sf_resos$rank2 - min
MAX_POINTS <- max(sf$points)
## normalize
graph_rank <- sf_resos$rank2
d_R <- data.frame(metric=factor("d_R"), rank=factor(graph_rank), value=sf_resos$distance / R)
o_1 <- data.frame(metric=factor("o_1"), rank=factor(graph_rank), value=sf_resos$nights_1month / 31)
o_2 <- data.frame(metric=factor("o_2"), rank=factor(graph_rank), value=sf_resos$nights_2month / 62)
o_3 <- data.frame(metric=factor("o_3"), rank=factor(graph_rank), value=sf_resos$nights_3month / 93)
weighted_points <- data.frame(metric=factor("weighted_points"), rank=factor(graph_rank), value=sf_resos$weighted_points)
weighted_distance <- data.frame(metric=factor("weighted_distance"), rank=factor(graph_rank), value=sf_resos$weighted_distance)
weighted_occupancy <- data.frame(metric=factor("weighted_occupancy"), rank=factor(graph_rank), value=sf_resos$weighted_occupancy)
# TODO there should be a better way
old_points <- data.frame(metric=factor("old_points"), rank=factor(graph_rank), value=sf_resos$points)
old_blended <- data.frame(metric=factor("old_blended"), rank=factor(graph_rank), value=sf_resos$points)
old_distance <- data.frame(metric=factor("old_distance"), rank=factor(graph_rank), value=sf_resos$distance * 500)
log_p <- data.frame(metric=factor("log_p"), rank=factor(graph_rank), value=sf_resos$points)
for (i in 1:nrow(log_p)) {
# Make log work. < 1 point are all treated as equally bad
if (log_p$value[i] < 1) {
log_p$value[i] = 0.0
}
else {
log_p$value[i] <- log10(log_p$value[i])
}
# Old blended
if (sf_resos$distance[i] < BLENDED_R) {
old_blended$value[i] = sf_resos$points[i]
}
else {
old_blended$value[i] = log10(sf_resos$points[i] / sf_resos$distance[i])
}
}
rank_data <- rbind(d_R, log_p, o_1, o_2, o_3)
## end normalize
old_rank_data <- rbind(old_blended, old_distance)
# ggplot(data=old_rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar(position=position_dodge())
new_rank_data <- rbind(weighted_points, weighted_distance, weighted_occupancy)
filename <- sprintf("out/weighted_blend_components_W_p=%f_W_d=%f_W_o=%f.pdf", W_p, W_d, W_o)
pdf(filename)
ggplot(data=new_rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar(position=position_dodge())
# ggplot(data=rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar()
library(ggplot2)
# Search radius (25mi is the default)
R <- 25.0
# Blended sort radius, based on bbox
BLENDED_R <- 16.39
# Distance is counted in increments of 0.1mi (old code)
MILES_INCR <- 0.1
# Take n samples
RESO_SAMPLES <- 50
# Or top n by rank
RANK_TOP_N <- 50
sf <- subset(read.table("in/sf_points_rank.2012-03-06.csv", sep="\t", header=TRUE), !duplicated(rank))
resos <- read.table("in/resos_3months_out.2012-03-07.csv", sep=",", header=TRUE)
sf_resos <- merge(sf, resos, by="hosting_id")
# Take random samples
sf_resos <- sf_resos[sample(1:nrow(sf_resos), RESO_SAMPLES, replace=FALSE),]
# Take top n
# sf_resos <- subset(sf_resos, rank > 0 & rank <= RANK_TOP_N)
## Additonal values
sf_resos$d_R <- sf_resos$distance / R
sf_resos$o_1 <- sf_resos$nights_1month / 31
sf_resos$o_2 <- sf_resos$nights_2month / 62
sf_resos$o_3 <- sf_resos$nights_3month / 93
for (i in 1:nrow(sf_resos)) {
# Make log work. < 1 point are all treated as equally bad
if (sf_resos$points[i] < 1) {
sf_resos$log_p[i] = 0.0
}
else {
sf_resos$log_p[i] <- log10(sf_resos$points[i])
}
}
# Weights
W_p <- 0.3 # Note: points aren't normalized. The max is around 2000, so 0.3 * log10() gives just under 1.0
W_d <- -0.6
W_o <- -0.2
sf_resos$weighted_points <- W_p * sf_resos$log_p
sf_resos$weighted_distance <- W_d * sf_resos$d_R
sf_resos$weighted_occupancy <- W_o * sf_resos$o_1
sf_resos$rank2 <- sf_resos$weighted_points + sf_resos$weighted_distance + sf_resos$weighted_occupancy
# min <- min(sf_resos$rank2)
# sf_resos$rank2 <- sf_resos$rank2 - min
MAX_POINTS <- max(sf$points)
## normalize
graph_rank <- sf_resos$rank2
d_R <- data.frame(metric=factor("d_R"), rank=factor(graph_rank), value=sf_resos$distance / R)
o_1 <- data.frame(metric=factor("o_1"), rank=factor(graph_rank), value=sf_resos$nights_1month / 31)
o_2 <- data.frame(metric=factor("o_2"), rank=factor(graph_rank), value=sf_resos$nights_2month / 62)
o_3 <- data.frame(metric=factor("o_3"), rank=factor(graph_rank), value=sf_resos$nights_3month / 93)
weighted_points <- data.frame(metric=factor("weighted_points"), rank=factor(graph_rank), value=sf_resos$weighted_points)
weighted_distance <- data.frame(metric=factor("weighted_distance"), rank=factor(graph_rank), value=sf_resos$weighted_distance)
weighted_occupancy <- data.frame(metric=factor("weighted_occupancy"), rank=factor(graph_rank), value=sf_resos$weighted_occupancy)
# TODO there should be a better way
old_points <- data.frame(metric=factor("old_points"), rank=factor(graph_rank), value=sf_resos$points)
old_blended <- data.frame(metric=factor("old_blended"), rank=factor(graph_rank), value=sf_resos$points)
old_distance <- data.frame(metric=factor("old_distance"), rank=factor(graph_rank), value=sf_resos$distance * 500)
log_p <- data.frame(metric=factor("log_p"), rank=factor(graph_rank), value=sf_resos$points)
for (i in 1:nrow(log_p)) {
# Make log work. < 1 point are all treated as equally bad
if (log_p$value[i] < 1) {
log_p$value[i] = 0.0
}
else {
log_p$value[i] <- log10(log_p$value[i])
}
# Old blended
if (sf_resos$distance[i] < BLENDED_R) {
old_blended$value[i] = sf_resos$points[i]
}
else {
old_blended$value[i] = log10(sf_resos$points[i] / sf_resos$distance[i])
}
}
rank_data <- rbind(d_R, log_p, o_1, o_2, o_3)
## end normalize
old_rank_data <- rbind(old_blended, old_distance)
# ggplot(data=old_rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar(position=position_dodge())
new_rank_data <- rbind(weighted_points, weighted_distance, weighted_occupancy)
filename <- sprintf("out/weighted_blend_components_W_p=%f_W_d=%f_W_o=%f.pdf", W_p, W_d, W_o)
pdf(filename)
ggplot(data=new_rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar(position=position_dodge())
# ggplot(data=rank_data, aes(x=rank, y=value, fill=metric)) + geom_bar()
install.packages('e1071')
library("e1071")
?svm
data <- read.table("/Users/tobi/Projects/auto_pricing/data.csv")
data <- read.table("/Users/tobi/Projects/auto_pricing/data.csv", sep=",")
View(data)
m <- svm(data$V7, data$V1)
data <- read.table("/Users/tobi/Projects/auto_pricing/data.csv", sep=",", header=TRUE)
View(data)
m <- svm(data$country_state_city_neighborhood, data$price)
m <- svm(as.factor(data$country_state_city_neighborhood), data$price)
data_clean <- subset(data, !is.na(country_state_city_neighborhood))
m <- svm(as.factor(data$square_feet, data$price)
)
m <- svm(data$square_feet, data$price)
x <- seq(0.1, 5, by = 0.05)
y <- log(x) + rnorm(x, sd = 0.2)
fix(x)
m <- svm(x, y)
new <- predict(m, x)
plot(x, y)
points(x, log(x), col = 2)
points(x, new, col = 4)
X <- data.frame(a = rnorm(1000), b = rnorm(1000))
attach(X)
m <- svm(X)
View(X)
m <- svm(~a + b)
predict(m, t(c(0, 0)))
data <- read.table("/Users/tobi/Desktop/data.csv")
data <- read.table("/Users/tobi/Desktop/data.csv", sep="\t")
View(data)
data <- read.table("/Users/tobi/Desktop/data.csv", sep=",")
View(data)
data <- read.table("/Users/tobi/Desktop/data.csv", sep=",", header=TRUE)
View(data)
data$0
data$1
data[1]
data[0]
data[2]
plot(data[1], data[2])
plot(data[2])
plot(data[1], data[2])
plot(data[1], data[3])
library("ggplot2")
qplot
qplot(data[1], data[2])
qplot(x=data[1], y=data[2])
data <- read.table("/Users/tobi/Desktop/data.csv", sep=",", header=TRUE)
plot(data)
data <- read.table("/Users/tobi/Desktop/data.csv", sep=",", header=TRUE)
library("ggplot2")
qplot(date, fees, data=data)
qplot(date, fees, data=data, geom=c("point", "smooth"))
qplot(date, fees, data=data, geom=c("point", "smooth"), group=1)
data2011 <- read.table("/Users/tobi/Desktop/data_2011.csv", sep=",", header=TRUE)
View(data2011)
qplot(date, fees, data=data2011, geom=c("point", "smooth"), group=1)
qplot(date, fees, data=data, geom=c("point", "smooth"), group=1)
qplot(date, fees, data=data2011, geom=c("point", "smooth"), group=1)
qplot(date, fees, data=data, geom=c("point", "smooth"), group=1)
data_all <- read.table("/Users/tobi/Desktop/data_all.csv", sep=",", header=TRUE)
qplot(date, fees, data=data_all, geom=c("point", "smooth"), group=1)
data_all <- read.table("/Users/tobi/Desktop/data_2011_present.csv", sep=",", header=TRUE)
qplot(date, fees, data=data_all, geom=c("point", "smooth"), group=1)
View(data_all)
data_all <- read.table("/Users/tobi/Desktop/data_all.csv", sep=",", header=TRUE)
qplot(date, fees, data=data_all, geom=c("point", "smooth"), group=1)
library("ggplot2")
data <- read.table("~/all_posts.csv")
d <- read.tabl('statsd_data.txt')
d <- read.table('statsd_data.txt')
View(d)
r <- signif(d, 2)
View(r)
f <- fft(r)
f <- fft(r$V1)
fix(f)
plot(f)
plot(r)
describe(r)
describe(r)
summary(r)
stddev(r)
std(r)
hist(r)
hist(r$V1)
hist(d$V1)
hist(d$V1, breaks=10)
hist(d$V1, breaks=30)
hist(d$V1, breaks=20)
hist(d$V1, breaks=50)
hist(d$V1, breaks=60)
hist(d$V1, breaks=100)
hist(d$V1, breaks=50)
summary(d$V1)
setwd("~/Projects/service_router/client")
data <- read.table("bench_rewrite_config.dat")
View(data)
library("ggplot2")
qplot(data)
qplot(data, V3, geom="line")
qplot(V2, V3, data=data, geom="line")
qplot(V2, V3, data=data, geom="line", facets=V1)
qplot(V2, V3, data=data, geom="line", facets=data$V1)
qplot(V2, V3, data=data, geom="line", facets=as.factor(V1))
qplot(V2, V3, data=data, geom="line", facets=as.factor(data$V1))
qplot(V2, V3, data=data, geom="line", facets=as.factor(V1) ~ .)
qplot(V2, V3, data=data, geom="line", facets=V1 ~ .)
qplot(V2, V3, data=data, geom="line", colour=V1 ~ .)
qplot(V2, V3, data=data, geom="line", colour=V1)
qplot(V2, V3, data=data, geom="line", colour=V1, ylim=c(0, 9999))
qplot(V2, V3, data=data, geom="line", colour=V1, ylim=c(999, 9999))
qplot(V2, V3, data=data, geom="line", colour=V1, ylim=c(1000, 6000))
qplot(V2, V3, data=data, geom="line", colour=V1, ylim=c(1000, 5000))
qplot(V2, V3, data=data, geom="line", colour=as.factor(V1), ylim=c(1000, 5000))
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 5000))
data <- read.table("bench_rewrite_config.dat")
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 5000))
qplot(V2, V3, data=data, colour=as.factor(V1))
qplot(V2, V3, data=data[10:], colour=as.factor(V1))
qplot(V2, V3, data=data[10], colour=as.factor(V1))
qplot(V2, V3, data=data[10], colour=as.factor(V1))
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 25000))
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 20000))
data <- read.table("bench_rewrite_config.dat")
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 20000))
qplot(V2, V3, data=data, colour=as.factor(V1), ylim=c(1000, 20000))
